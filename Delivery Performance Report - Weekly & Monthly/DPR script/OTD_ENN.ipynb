{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d2398f-225a-4b67-8630-2cf68b70b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from pandas.tseries.offsets import BDay\n",
    "import win32com.client\n",
    "import pytz\n",
    "from datetime import datetime,timedelta,date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6d770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_MCID = 0\n",
    "Path = r'E:\\_Projects\\Delivery Perforamce\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a6ecb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HT185078\\AppData\\Local\\Temp\\3\\ipykernel_29436\\345156821.py:48: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data_raw = pd.read_sql(query, con=conn)\n"
     ]
    }
   ],
   "source": [
    "import oracledb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "if SQL_MCID == 0:\n",
    "\n",
    "    # Enable thick mode\n",
    "    oracledb.init_oracle_client(lib_dir=r\"E:\\softwares\\instantclient-basic-windows.x64-23.5.0.24.07\\instantclient_23_5\")\n",
    "\n",
    "    # Connection details\n",
    "    dsn_tns = oracledb.makedsn('153.84.75.216', 1521, service_name='ebs_ATMPROD')\n",
    "\n",
    "\n",
    "    # Use a context manager to handle the connection\n",
    "    with oracledb.connect(user='erp_user', password='erp_pass', dsn=dsn_tns) as conn:\n",
    "        \n",
    "\n",
    "        query = f\"\"\"\n",
    "        select\n",
    "        pha.segment1 as PO,\n",
    "        pha.vendor_id as VID,\n",
    "        case\n",
    "         when pha.vendor_id='10013919' then 'JAB'\n",
    "         when pha.vendor_id='16783041' then 'ENN'\n",
    "         else 'USI'\n",
    "        end as SITE,\n",
    "        To_char(pll.need_by_date, 'DD-MON-YYYY') As NBD_dt,\n",
    "        To_char(pll.promised_date, 'DD-MON-YYYY') As PD_dt,\n",
    "        pll.revision_num,\n",
    "        pll.quantity as qty,\n",
    "        pll.LAST_UPDATE_DATE,\n",
    "        pll.APPROVED_DATE,\n",
    "        pha.CREATION_DATE\n",
    "        from\n",
    "        po_line_locations_archive_all pll,\n",
    "        po_headers_all pha\n",
    "        where\n",
    "        pll.po_header_id = pha.po_header_id\n",
    "        --and pha.segment1='5001502495'\n",
    "        and pha.vendor_id in (16783041,10013919,9401862) --16783041 ENNOCONN, 10013919 JABIL, 9401862 USI\n",
    "        and pha.creation_date>='01-JAN-23'\n",
    "        and pll.promised_date is not null\n",
    "        order by segment1, revision_num\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Fetch data into a pandas DataFrame and append to the main DataFrame\n",
    "        data_raw = pd.read_sql(query, con=conn)\n",
    "        \n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    data_raw.to_csv(Path+'Output\\\\ref\\\\PO_Details.csv', index=False)\n",
    "else:\n",
    "    data_raw = pd.read_csv(Path+'Output\\\\ref\\\\PO_Details.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8304559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HT185078\\AppData\\Local\\Temp\\3\\ipykernel_29436\\188796955.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  first_pocreation['SitePO'] = first_pocreation['SITE'] + first_pocreation['PO']\n"
     ]
    }
   ],
   "source": [
    "data_last = data_raw.copy()\n",
    "data_first = data_raw.copy()\n",
    "\n",
    "data_last.sort_values(by=['PO','SITE','LAST_UPDATE_DATE'])\n",
    "data_last.drop_duplicates(subset=['PO','SITE'], keep='last',inplace=True)\n",
    "# data_last.to_csv('E:\\_Projects\\splr_delivery\\snd\\data_last.csv',index= False)\n",
    "\n",
    "data_first.sort_values(by=['PO','SITE','LAST_UPDATE_DATE'])\n",
    "data_first.drop_duplicates(subset=['PO','SITE'], keep='first',inplace=True)\n",
    "data_first.to_csv('E:\\_Projects\\splr_delivery\\snd\\data_first.csv',index= False)\n",
    "\n",
    "data_first['PO']= data_first['PO'].astype(str)\n",
    "data_first['SITE']= data_first['SITE'].astype(str)\n",
    "first_pocreation = data_first[['SITE','PO','CREATION_DATE']]\n",
    "\n",
    "first_pocreation['SitePO'] = first_pocreation['SITE'] + first_pocreation['PO']\n",
    "first_pocreation.to_csv('E:\\_Projects\\splr_delivery\\snd\\pocreation.csv',index= False)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955788b",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab0baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20251203\n"
     ]
    }
   ],
   "source": [
    "dt = datetime.now()\n",
    "date_str = dt.strftime(\"%Y%m%d\")\n",
    "print(date_str)\n",
    "# data = pd.read_csv(r'./rcv/completion_po_'+date_str+'.csv', encoding='utf-8', low_memory=False)\n",
    "data = pd.read_csv(r'E:\\_Projects\\_outputs\\completion\\Completion PO\\completion_po_20251203.csv', encoding='utf-8', low_memory=False)\n",
    "data = data[['site','item','PO','ship_date','qty','item_type','ship_date_mth','class','prod_grp_wb']]\n",
    "data= data[data['site'].isin(['BUD','JAB'])]\n",
    "data= data[data['item_type'].isin(['M'])]\n",
    "data= data[~data['item'].str.contains('-KIT')]\n",
    "item = [202511]\n",
    "data = data[data['ship_date_mth'].isin(item)]\n",
    "data.to_csv('E:\\_Projects\\splr_delivery\\snd\\Shipped_data.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd9d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wrk = data[['site','PO','prod_grp_wb','class','item','item_type','ship_date','ship_date_mth','qty']]\n",
    "data_wrk['PO']= data_wrk['PO'].astype(str)\n",
    "data_last['PO']= data_last['PO'].astype(str)\n",
    "data_wrk.to_csv('E:\\_Projects\\splr_delivery\\snd\\data_wrk1.csv',index= False)\n",
    "data_wrk = data_wrk.merge(data_last[['PO','NBD_DT']], on='PO', how='left')\n",
    "\n",
    "data_wrk['NBD_DT'] = data_wrk['NBD_DT'].astype('datetime64[ns]')\n",
    "data_wrk = data_wrk.merge(data_first[['PO','PD_DT']], on='PO', how='left')\n",
    "\n",
    "data_wrk.rename(columns={'PD_DT' : 'Promise Dt (first)','NBD_DT':'Need By dt'}, inplace=True)\n",
    "data_wrk = data_wrk.merge(data_last[['PO','PD_DT']], on='PO', how='left')\n",
    "\n",
    "data_wrk.rename(columns={'PD_DT' : 'Promise Dt (last)'}, inplace=True)\n",
    "\n",
    "data_wrk = data_wrk.merge(data_first[['PO','APPROVED_DATE']], on='PO', how='left')\n",
    "data_wrk.rename(columns={'APPROVED_DATE' : 'Approved Dt(first)'}, inplace=True)\n",
    "\n",
    "data_wrk['Receipt Dt'] =''\n",
    "data_wrk['Receipt Dt'] = data_wrk['Receipt Dt'].astype('datetime64[ns]')\n",
    "data_wrk['ship_date'] = data_wrk['ship_date'].astype('datetime64[ns]')\n",
    "cond = data_wrk['site']=='JAB'\n",
    "data_wrk['Receipt Dt'] = np.where(cond,data_wrk['ship_date'] + BDay(5),data_wrk['ship_date'] )\n",
    "data_wrk['SitePO']= data_wrk['site'] + data_wrk['PO']\n",
    "data_wrk = data_wrk.merge(first_pocreation[['SitePO','CREATION_DATE']], on='SitePO', how='left')\n",
    "data_wrk.to_csv('E:\\_Projects\\splr_delivery\\snd\\data_wrk.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "999f1b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['site', 'PO', 'prod_grp_wb', 'class', 'item', 'item_type', 'ship_date',\n",
       "       'ship_date_mth', 'qty', 'Need By dt', 'Promise Dt (first)',\n",
       "       'Promise Dt (last)', 'Approved Dt(first)', 'Receipt Dt', 'SitePO',\n",
       "       'CREATION_DATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_result = data_wrk.copy()\n",
    "data_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be0fc0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_result['Delivery vs Orig PD'] =''\n",
    "data_result['Delivery vs Orig PD'] = data_result['Delivery vs Orig PD'].astype('datetime64[ns]')\n",
    "\n",
    "data_result['Receipt Dt'] = data_result['Receipt Dt'].astype('datetime64[ns]')\n",
    "data_result['Promise Dt (first)'] = data_result['Promise Dt (first)'].astype('datetime64[ns]')\n",
    "data_result['Delivery vs Orig PD'] = data_result['ship_date'] - data_result['Promise Dt (first)']\n",
    "data_result['Delivery vs Orig PD'] = data_result['Delivery vs Orig PD'] / np.timedelta64(1, 'D')\n",
    "\n",
    "cond1 = data_result['Delivery vs Orig PD'] <= -5\n",
    "cond2 = data_result['Delivery vs Orig PD'] <= 1\n",
    "data_result['Complianc Orig PD'] = np.where(cond1,'On-Time', \\\n",
    "                                           np.where(cond2,'On-Time','Late'))\n",
    "\n",
    "\n",
    "con1 = data_result['Delivery vs Orig PD'] <= 0\n",
    "con2 = data_result['Delivery vs Orig PD'] <= 1\n",
    "con3 = data_result['Delivery vs Orig PD'] <= 5\n",
    "con4 = data_result['Delivery vs Orig PD'] <= 10\n",
    "con5 = data_result['Delivery vs Orig PD'] <= 20\n",
    "con6 = data_result['Delivery vs Orig PD'] <= 30\n",
    "data_result['Perf Category Orig PD'] = np.where(con1,'Early', \\\n",
    "                                               np.where(con2,'On-Time', \\\n",
    "                                                        np.where(con3,'1) 1-5 Days Late', \\\n",
    "                                                           np.where(con4,'2) 5-10 Days Late', \\\n",
    "                                                               np.where(con5,'3) 10-20 Days Late', \\\n",
    "                                                                    np.where(con6,'4) 20-30 Days Late','5) 30+ Days Late'))))))\n",
    "\n",
    "\n",
    "data_result['Promise Dt (last)'] = data_result['Promise Dt (last)'].astype('datetime64[ns]')\n",
    "\n",
    "#data_result['Need By dt']= pd.to_datetime(data['Need By dt'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "\n",
    "data_result['Need By dt'] = pd.to_datetime(data_result['Need By dt']).dt.date\n",
    "data_result['Promise Dt (first)'] = pd.to_datetime(data_result['Promise Dt (first)']).dt.date\n",
    "data_result['Promise Dt (last)'] = pd.to_datetime(data_result['Promise Dt (last)']).dt.date\n",
    "data_result['Promise Dt (last)'] = pd.to_datetime(data_result['Promise Dt (last)']).dt.date\n",
    "data_result['Receipt Dt'] = pd.to_datetime(data_result['Receipt Dt']).dt.date\n",
    "# data_result['PO Creation Dt'] = pd.to_datetime(data_result['PO Creation Dt']).dt.date\n",
    "\n",
    "\n",
    "\n",
    "data_result['site']=data_result['site'].replace({'BUD':'ENN'})\n",
    "\n",
    "data_result.rename(columns={'item' : 'PN','ship_date':'SHIPPED DATE','qty':'Qty','CREATION_DATE':'PO Creation Dt','item_type':'PID Type','prod_grp_wb':'Prod Grp','ship_date_mth':'Ship Period','class':'Class'}, inplace=True)\n",
    "\n",
    "data_result.drop(columns={'SitePO'}, axis=1, inplace=True)    \n",
    "\n",
    "data_result['IO Booked Dt(First)']=''\n",
    "data_result['IO Booked Dt(Last)']=''\n",
    "data_result['Booked Dt']=''\n",
    "\n",
    "                           \n",
    "Source = data_result[['site','PO','Prod Grp','Class','PN','PID Type','SHIPPED DATE','Ship Period','Qty','Need By dt','Booked Dt','Promise Dt (first)','Promise Dt (last)','Receipt Dt','PO Creation Dt','Delivery vs Orig PD','Complianc Orig PD','Perf Category Orig PD']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01589555-4b14-418b-bc46-6b7d106746e5",
   "metadata": {},
   "source": [
    "## OTD Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b9f5ab-d192-420c-8ca3-f4f9e7d6fcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HT185078\\AppData\\Local\\Temp\\3\\ipykernel_29436\\1023442606.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Source['Class'] = Source['Class'].astype('str')\n"
     ]
    }
   ],
   "source": [
    "Product = pd.read_csv(Path+'Input\\\\class_offerpf_map.csv')\n",
    "\n",
    "\n",
    "\n",
    "Source['Class'] = Source['Class'].astype('str')\n",
    "Product['Class'] = Product['Class'].astype('str')\n",
    "\n",
    "Data = pd.merge(Source, Product[['Class','Offer PF']], on='Class',how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd04fa0a-feb8-413e-9566-e3092c26c058",
   "metadata": {},
   "source": [
    "#### Update from EUMOCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4da3308c-c9b5-4e40-b539-fa4e33022841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATM_V1.csv\n",
      "ATM_V2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HT185078\\AppData\\Local\\Temp\\3\\ipykernel_29436\\150145941.py:11: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(Consolidation_Path, file_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATM_V3.csv\n",
      "ATM_V4.csv\n",
      "ATM_V5.csv\n",
      "ATM_V6.csv\n",
      "ATM_V7.csv\n",
      "ATM_V8.csv\n",
      "ATM_V9.csv\n"
     ]
    }
   ],
   "source": [
    "Consolidation_Path = Path+'Consolidation\\\\'\n",
    "\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file_name in os.listdir(Consolidation_Path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        \n",
    "        print(file_name)\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(Consolidation_Path, file_name))\n",
    "        dfs.append(df)\n",
    "\n",
    "Consolidation = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "#Consolidation.to_csv(Consolidation_Path+'Consolidate.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbd131d0-6faa-4fbf-be8e-72b01ea51aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Consolidation = Consolidation[['Org Code', 'Region', 'Customer_End Customer','Booked Dt','PID','PO No.','filref']]\n",
    "\n",
    "Consolidation.drop_duplicates(subset=['PID','PO No.', 'Booked Dt'], inplace=True)\n",
    "\n",
    "Consolidation = Consolidation[Consolidation['PO No.'].notnull()]\n",
    "\n",
    "Consolidation = Consolidation[Consolidation['Booked Dt'].notnull()]\n",
    "\n",
    "Consolidation['PO No.'] = Consolidation['PO No.'].astype(str)\n",
    "\n",
    "val = {'PO No.':'PO','PID':'PN'}\n",
    "Consolidation.rename(columns= val, inplace=True)\n",
    "Consolidation['PO'] = Consolidation['PO'].astype(str)\n",
    "\n",
    "Consolidation['PO'] = Consolidation['PO'].str.replace('.0', '', regex=False)\n",
    "Data['PO'] = Data['PO'].str.replace('.0', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b04365-f408-45ee-8e0a-27c09c636fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dt = Consolidation.copy()\n",
    "last_dt = Consolidation.copy()\n",
    "\n",
    "first_dt.sort_values(by=['filref'])\n",
    "first_dt.drop_duplicates(subset=['PN','PO'], keep='first', inplace=True)\n",
    "\n",
    "last_dt.sort_values(by=['filref'])\n",
    "last_dt.drop_duplicates(subset=['PN','PO'], keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a48f03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "872d0adc-d59b-4915-9a52-f557d79a7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.merge(Data , first_dt, on=['PN','PO'], how='left')\n",
    "Data = pd.merge(Data , last_dt, on=['PN','PO'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f06a81fe-2989-4018-9397-2280ea293f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Booked Dt'] = Data['Booked Dt_y']\n",
    "Data.rename(columns={'Region_x':'Region'}, inplace=True)\n",
    "Data['Customer Name'] = Data['Customer_End Customer_x']\n",
    "Data['Country'] = Data['Org Code_x']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4181571-3f69-4cf8-bc68-ad30e6aefd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each column to datetime format\n",
    "date_columns = [\n",
    "    'SHIPPED DATE',\n",
    "    'Booked Dt',\n",
    "    'Promise Dt (first)',\n",
    "    'Promise Dt (last)',\n",
    "    'Need By dt'\n",
    "]\n",
    "\n",
    "for col in date_columns:\n",
    "    Data[col] = pd.to_datetime(Data[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15657e97-f175-4b41-9d62-2023636349cb",
   "metadata": {},
   "source": [
    "### Create Dummy Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8128ab7c-45d9-48d1-ace7-6278a905d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "val= ['Act Lt','Act Lt Wks','Act LT Wks Oride','System LT','System LT Wks','Act LT vs System LT','Factory LT','Factory LT Wks','Inventory Item Serial Number','Tracer Number','Manufactured Dt','SSD Wk','Month','Detail comments','Responsibility','Reason','Reason Code','Dataref','Reason Code Groom']\n",
    "\n",
    "for col in val:\n",
    "    Data[col] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "653d884d-1649-4820-855d-e029a1e7c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[['site','PO','Prod Grp','Class','PN','PID Type','SHIPPED DATE','Ship Period','Qty','Need By dt','Booked Dt','Promise Dt (first)','Promise Dt (last)','Receipt Dt','PO Creation Dt','Delivery vs Orig PD','Complianc Orig PD','Perf Category Orig PD','Act Lt','Act Lt Wks','Act LT Wks Oride','System LT','System LT Wks','Act LT vs System LT','Factory LT','Factory LT Wks','Inventory Item Serial Number','Tracer Number','Manufactured Dt','Offer PF','Customer Name','Country','Region','SSD Wk','Month','Detail comments','Responsibility','Reason','Reason Code','Dataref','Reason Code Groom']].to_excel(Path+'Output\\\\OTD_Metrics_ENN.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
