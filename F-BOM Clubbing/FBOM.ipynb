{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "639a5d23-56bb-4637-8eaf-21dfd40d96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "Path = r'E:\\_Projects\\FBOM\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bb752cc-45f2-4a45-85a5-a7606dc513ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\2012.xls',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\2018.xls',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\2019.xls',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\2063.xls',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\6623.xls',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\6624.xls',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\6627.xls',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\6628.xls',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\6681.xls',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\6682.xls',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\6684.xls',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\6688.xls']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Folder path\n",
    "folder_path = Path + 'Input\\\\'\n",
    "\n",
    "# Initialize as DataFrames\n",
    "final_ = pd.DataFrame()\n",
    "data_Var_Bk_ = pd.DataFrame()\n",
    "combination = pd.DataFrame()\n",
    "default = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "files = glob.glob(folder_path + '????.xls')\n",
    "files_excel = glob.glob(folder_path + '????.xlsx')\n",
    "\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e28d0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\2062.xlsx',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\2064.xlsx',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\2084.xlsx',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\2088.xlsx',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\6629.xlsx',\n",
       " 'E:\\\\_Projects\\\\FBOM\\\\\\\\Input\\\\6658.xlsx']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "def45042-1248-437a-ba5a-6bed91d3b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Config_Single_Class(x,model_class):\n",
    "    global data_PPL\n",
    "    global data\n",
    "    global data_Var\n",
    "    \n",
    "    if model_class == '2019':\n",
    "        \n",
    "        data_PPL= pd.read_excel(Path+'Input\\\\2019.xls', sheet_name='PPL Sets')\n",
    "        data_PPL.drop(columns=data_PPL.columns[1], inplace=True)\n",
    "        data = pd.read_excel(x, sheet_name='Combinations and Defaults')\n",
    "        data_Var = pd.read_excel(x, sheet_name='Variants and Options')\n",
    "\n",
    "    elif model_class == '2018':\n",
    "        data_PPL= pd.read_excel(Path+'Input\\\\2018.xls', sheet_name='PPL Sets', header=None)\n",
    "        data_PPL.rename(columns = {data_PPL.columns[0] :'Item',data_PPL.columns[1] :'Description',data_PPL.columns[2] :'Features'}, inplace=True)\n",
    "        data = pd.read_excel(x, sheet_name='Combinations and Defaults')\n",
    "        data_Var = pd.read_excel(x, sheet_name='Variants and Options')\n",
    "    \n",
    "    \n",
    "    elif model_class == '2062':\n",
    "        data_PPL= pd.read_excel(Path+'Input\\\\2062.xlsx', sheet_name='PPL Sets', header=None)\n",
    "        data_PPL.rename(columns = {data_PPL.columns[0] :'Item',data_PPL.columns[1] :'Description',data_PPL.columns[2] :'Features'}, inplace=True)\n",
    "\n",
    "        data = pd.read_excel(x, sheet_name='Combinations and Defaults')\n",
    "        data_Var = pd.read_excel(x, sheet_name='Variants and Options')\n",
    "\n",
    "\n",
    "    elif model_class == '2063':\n",
    "        \n",
    "        data= pd.read_excel(Path+'Input\\\\2063.xls', sheet_name='combi+defaults')\n",
    "#         values = [data.columns[1]]\n",
    "#         data.drop(columns=values, inplace=True)\n",
    "#         data.insert(2, 'Dummy', np.nan)\n",
    "\n",
    "\n",
    "        data_PPL = pd.read_excel(x, sheet_name='ppl sets')\n",
    "        data_Var = pd.read_excel(x, sheet_name='variants and options')\n",
    "\n",
    "    \n",
    "    elif model_class == '2064':\n",
    "        data_PPL= pd.read_excel(Path+'Input\\\\2064.xlsx', sheet_name='PPL Sets', header=None)\n",
    "        data_PPL.columns = ['Item','Description','Features']\n",
    "        \n",
    "        data = pd.read_excel(x, sheet_name='Combinations and Defaults')\n",
    "        #Update Default in empty row\n",
    "        data.iloc[:, 0] = data.iloc[:, 0].fillna('')\n",
    "        row_number = data.index[data.iloc[:, 0].str.contains('DF01')].tolist()[0] - 1\n",
    "        data.iloc[row_number, 0] = 'Defaults'\n",
    "\n",
    "\n",
    "        data_Var = pd.read_excel(x, sheet_name='Variants and Options')\n",
    "\n",
    "    elif model_class == '6623':\n",
    "        data= pd.read_excel(Path+'Input\\\\6623.xls', sheet_name='combi+defaults')\n",
    "        values = [data.columns[1],data.columns[2]]\n",
    "        data.drop(columns=values, inplace=True)\n",
    "        data.insert(2, 'Dummy', np.nan)\n",
    "\n",
    "\n",
    "        data_PPL = pd.read_excel(x, sheet_name='ppl sets')\n",
    "        data_Var = pd.read_excel(x, sheet_name='variants and options')\n",
    "\n",
    "    elif model_class == '6627':\n",
    "  \n",
    "        data= pd.read_excel(Path+'Input\\\\6627.xls', sheet_name='Combinations and Defaults')\n",
    "        values = [data.columns[1],data.columns[2]]\n",
    "        data.drop(columns=values, inplace=True)\n",
    "        data.insert(2, 'Dummy', np.nan)\n",
    "\n",
    "\n",
    "        data_PPL = pd.read_excel(x, sheet_name='PPL Sets')\n",
    "        data_Var = pd.read_excel(x, sheet_name='Variants and Options')\n",
    "\n",
    "    elif model_class == '6628':\n",
    "        data= pd.read_excel(Path+'Input\\\\6628.xls', sheet_name='Combinations and Defaults')\n",
    "        values = [data.columns[1],data.columns[2],data.columns[5]]\n",
    "        data.drop(columns=values, inplace=True)\n",
    "        data.insert(2, 'Dummy', np.nan)\n",
    "\n",
    "\n",
    "        data_PPL = pd.read_excel(x, sheet_name='PPL Sets')\n",
    "        data_Var = pd.read_excel(x, sheet_name='Variants and Options')\n",
    "        \n",
    "    elif model_class == '6658':\n",
    "        data= pd.read_excel(Path+'Input\\\\6658.xlsx', sheet_name='Combinations and Defaults')\n",
    "        values = [data.columns[1],data.columns[2],data.columns[3]]\n",
    "        data.drop(columns=values, inplace=True)\n",
    "        data.insert(2, 'Dummy', np.nan)\n",
    "\n",
    "\n",
    "        data_PPL = pd.read_excel(x, sheet_name='PPL Sets')\n",
    "        data_PPL.rename(columns = {data_PPL.columns[0] :'Item',data_PPL.columns[1] :'Description',data_PPL.columns[2] :'Features'}, inplace=True)\n",
    "\n",
    "        \n",
    "        data_Var = pd.read_excel(x, sheet_name='Variants and Options')\n",
    "        \n",
    "        values = [data_Var.columns[1]]\n",
    "        data_Var.drop(columns=values, inplace=True)\n",
    "\n",
    "    elif model_class == '6659':\n",
    "        data= pd.read_excel(Path+'Input\\\\6659.xlsx', sheet_name='Combinations and Defaults')\n",
    "        data_PPL = pd.read_excel(x, sheet_name='PPL Sets')\n",
    "        data_PPL.rename(columns = {data_PPL.columns[0] :'Item',data_PPL.columns[1] :'Description',data_PPL.columns[2] :'Features'}, inplace=True)\n",
    "\n",
    "        \n",
    "        data_Var = pd.read_excel(x, sheet_name='Variants and Options')\n",
    "        \n",
    "        values = [data_Var.columns[1]]\n",
    "        data_Var.drop(columns=values, inplace=True)\n",
    "\n",
    "    elif model_class == '6680':\n",
    "        data= pd.read_excel(Path+'Input\\\\6680.xls', sheet_name='Mfg Features')\n",
    "        values = [data.columns[1],data.columns[2]]\n",
    "        data.drop(columns=values, inplace=True)\n",
    "        data.insert(2,'Dummy', np.nan)\n",
    "\n",
    "\n",
    "        data_PPL = pd.read_excel(x, sheet_name='PPL Sets')\n",
    "        data_Var = pd.read_excel(x, sheet_name='Orderable Features')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def Config_Multi_Class(x,model_class):\n",
    "    global data_PPL\n",
    "    global data\n",
    "    global data_defaults\n",
    "    global data_Var\n",
    "\n",
    "\n",
    "    if model_class == '6681':\n",
    "        data= pd.read_excel(Path+'Input\\\\6681.xls', sheet_name='combinations ')\n",
    "        values = [data.columns[0]]\n",
    "        data.drop(columns=values, inplace=True)\n",
    "\n",
    "\n",
    "        data_defaults = pd.read_excel(x, sheet_name='defaults ')\n",
    "        data_PPL = pd.read_excel(x, sheet_name='PPL Sets')\n",
    "        data_Var = pd.read_excel(x, sheet_name='Orderable Features ')\n",
    "\n",
    "\n",
    "    elif model_class == '6624':\n",
    "        data_PPL= pd.read_excel(Path+'Input\\\\6624.xls', sheet_name='PPL Sets24', header=None)\n",
    "        data_PPL = data_PPL.drop(index=0)\n",
    "        data_PPL.columns = data_PPL.iloc[0]\n",
    "        data_PPL = data_PPL[1:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "        data = pd.read_excel(x, sheet_name='combinations24')\n",
    "        data_defaults = pd.read_excel(x, sheet_name='defaults24')\n",
    "        data_Var = pd.read_excel(x, sheet_name='Orderable Features24')\n",
    "   \n",
    "    elif model_class == '6629':\n",
    "        data_PPL= pd.read_excel(Path+'Input\\\\6629.xlsx', sheet_name='PPL Sets29', header=None)\n",
    "        data_PPL.rename(columns = {data_PPL.columns[0] :'Item',data_PPL.columns[1] :'Description',data_PPL.columns[2] :'Features'}, inplace=True)\n",
    "        data = pd.read_excel(x, sheet_name='combinations29')\n",
    "        data_defaults = pd.read_excel(x, sheet_name='defaults29')\n",
    "        data_Var = pd.read_excel(x, sheet_name='Orderable Features29') \n",
    "        \n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29d1858b-3aad-4b16-9436-1d85f57ab6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Folder path\n",
    "folder_path = Path + 'Input\\\\'\n",
    "\n",
    "# Initialize as DataFrames\n",
    "final_ = pd.DataFrame()\n",
    "data_Var_Bk_ = pd.DataFrame()\n",
    "combination = pd.DataFrame()\n",
    "default = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "files = glob.glob(folder_path + '????.xls')\n",
    "\n",
    "def Single_Class(x,model_class):\n",
    "    global final_\n",
    "    global data_Var_Bk_\n",
    "    global final\n",
    "    global data_PPL\n",
    "    global data_Var\n",
    "    global data\n",
    "\n",
    "    if model_class in ['2018','2019','2062','2063','2064','6623','6627','6628','6658','6680','6659']:\n",
    "        Config_Single_Class(x,model_class)\n",
    "   \n",
    "    else:   \n",
    "        data = pd.read_excel(x, sheet_name='Combinations and Defaults')\n",
    "        data_PPL = pd.read_excel(x, sheet_name='PPL Sets')\n",
    "        data_Var = pd.read_excel(x, sheet_name='Variants and Options')\n",
    "        \n",
    "    data_PPL = data_PPL.dropna(how='all').replace('', pd.NA).dropna(how='all')\n",
    "    data_Var = data_Var.dropna(how='all').replace('', pd.NA).dropna(how='all')\n",
    "    \n",
    "    # Single\n",
    "    data.iloc[:, 1] = data.iloc[:, 1].astype(str).str.strip()\n",
    "    data.iloc[:, 0] = data.apply(\n",
    "        lambda row: model_class + \"-\" + row[data.columns[1]] if pd.notnull(row[data.columns[1]]) and row[data.columns[1]] != 'nan' else row[data.columns[0]],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    values = {data.columns[0]: 'Item', data.columns[1]: 'Group', data.columns[3]: 'Description', data.columns[4]: 'Features'}\n",
    "    data.rename(columns=values, inplace=True)\n",
    "\n",
    "    data.loc[data['Item'].isin(['DEFAULTS','DEFAULT PPLS']),'Item'] = 'Defaults'\n",
    "    \n",
    "    try:\n",
    "        row_number = data.index[data['Item'] == 'Defaults'].tolist()\n",
    "    except:\n",
    "        print('Default not found')\n",
    "    \n",
    "    if not row_number:\n",
    "        #row_number = (data.index[data['Item'] == 'DF01'].tolist())-1\n",
    "        \n",
    "        row_number = data.index[data['Item'] == 'DF01'].tolist()\n",
    "\n",
    "        \n",
    "    print(row_number)\n",
    "    \n",
    "    #data.to_csv(Path+'Output\\combi.csv',index=False)\n",
    "    #combination = data.iloc[1:row_number[0] - 3]\n",
    "    combination = data.iloc[1:row_number[0] - 1]\n",
    "    default = data.iloc[row_number[0]:data.shape[0] + 1]\n",
    "\n",
    "    \n",
    "    #combination.to_csv(Path+'Output\\combi1.csv',index=False)\n",
    "    \n",
    "    \n",
    "    combination = combination.dropna(how='all').replace('', pd.NA).dropna(how='all')\n",
    "    default = default.dropna(how='all').replace('', pd.NA).dropna(how='all')\n",
    "    default.iloc[:, 4] = \"absence of \" + default.iloc[:, 4]\n",
    "\n",
    "    ######################\n",
    "    #combination.to_csv(Path+'Output\\combi2.csv',index=False)\n",
    "    \n",
    "    values = {data_PPL.columns[0]: 'Group'}\n",
    "    data_PPL.rename(columns=values, inplace=True)\n",
    "    data_PPL.iloc[:, 0] = data_PPL.iloc[:, 0].astype(str).str.strip()\n",
    "    data_PPL['Item'] = data_PPL.apply(\n",
    "        lambda row: model_class + \"-\"  + row[data_PPL.columns[0]] if pd.notnull(row[data_PPL.columns[0]]) and row[data_PPL.columns[0]] != 'nan' else row[data_PPL.columns[0]],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    values = {data_Var.columns[0]: 'Group', data_Var.columns[3]: 'Features'}\n",
    "    data_Var.rename(columns=values, inplace=True)\n",
    "    data_Var['Group'] = data_Var['Group'].fillna(method='ffill')\n",
    "    data_Var.loc[(data_Var['Features'].notnull()) & (data_Var['Features'] != 'nan'), 'Item'] = model_class + '-' + data_Var['Features']\n",
    "    data_Var['Item'] = data_Var['Item'].astype(str)\n",
    "    \n",
    "    data_Var['Group'] = model_class +'-'+ data_Var['Group']\n",
    "    data_Var_Bk = data_Var.copy()\n",
    "    data_Var = data_Var.dropna(subset=['Item'])\n",
    "    data_Var = data_Var[data_Var['Item'] != 'nan']\n",
    "\n",
    "    Grouped_var = data_Var.groupby('Group')['Features'].apply(lambda x: ' or '.join(x)).reset_index()\n",
    "    values = {'Item': 'Features', 'Group': 'Item'}\n",
    "    Grouped_var.rename(columns=values, inplace=True)\n",
    "\n",
    "    default['ref'] = 'default'\n",
    "    combination['ref'] = 'combination'\n",
    "    data_PPL['ref'] = 'PPL'\n",
    "    Grouped_var['ref'] = 'Variants_Options'\n",
    "\n",
    "    final = pd.concat([default, combination, data_PPL, Grouped_var], ignore_index=True)\n",
    "    values = {'Item': 'Group', 'Features': 'comibined_features'}\n",
    "    Grouped_var.rename(columns=values, inplace=True)\n",
    "    data_Var_Bk = pd.merge(data_Var_Bk, Grouped_var, on='Group', how='left')\n",
    "\n",
    "    final['Class'] = model_class\n",
    "    data_Var_Bk['Class'] = model_class\n",
    "\n",
    "    final_ = pd.concat([final_, final], axis=0)\n",
    "    data_Var_Bk_ = pd.concat([data_Var_Bk_, data_Var_Bk], axis=0)\n",
    "\n",
    "def Multi_Class(x, model_class):\n",
    "    global final_\n",
    "    global data_Var_Bk_\n",
    "    global final\n",
    "    global data_PPL\n",
    "    global data_Var\n",
    "    global data\n",
    "    global data_defaults\n",
    "\n",
    "    if model_class in ['6681','6624','6629']:\n",
    "        Config_Multi_Class(x,model_class)\n",
    "   \n",
    "    else:  \n",
    "        data = pd.read_excel(x, sheet_name='combinations ')\n",
    "        data_defaults = pd.read_excel(x, sheet_name='defaults')\n",
    "        data_PPL = pd.read_excel(x, sheet_name='PPL Sets')\n",
    "        data_Var = pd.read_excel(x, sheet_name='Orderable Features')\n",
    "        \n",
    "    data_PPL = data_PPL.dropna(how='all').replace('', pd.NA).dropna(how='all')\n",
    "    data_Var = data_Var.dropna(how='all').replace('', pd.NA).dropna(how='all')\n",
    "    \n",
    "    # Multi\n",
    "    data_defaults.iloc[:, 1] = data_defaults.iloc[:, 1].astype(str).str.strip()\n",
    "    data_defaults.iloc[:, 0] = data_defaults.apply(\n",
    "        lambda row: model_class + \"-\" + row[data_defaults.columns[1]] if pd.notnull(row[data_defaults.columns[1]]) and row[data_defaults.columns[1]] != 'nan' else row[data_defaults.columns[0]],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    values = {data_defaults.columns[0]: 'Item', data_defaults.columns[1]: 'Group', data_defaults.columns[3]: 'Description', data_defaults.columns[4]: 'Features'}\n",
    "    data_defaults.rename(columns=values, inplace=True)\n",
    "    \n",
    "    ## Combination  \n",
    "    \n",
    "    data.iloc[:, 0] = data.iloc[:, 0].astype(str).str.strip()\n",
    "    \n",
    "    \n",
    "    \n",
    "    if data.shape[1] < 5:\n",
    "        data['new_column'] = None\n",
    "\n",
    "    # Apply your function\n",
    "    data.iloc[:, 4] = data.apply(\n",
    "        lambda row: model_class + \"-\" + row[data.columns[0]] if pd.notnull(row[data.columns[0]]) and row[data.columns[0]] != 'nan' else row[data.columns[0]],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    values = {data.columns[4]: 'Item', data.columns[0]: 'Group', data.columns[1]: 'Description', data.columns[2]: 'Features'}\n",
    "    data.rename(columns=values, inplace=True)\n",
    "    \n",
    "    combination = data\n",
    "    default = data_defaults\n",
    "\n",
    "    combination = combination.dropna(how='all').replace('', pd.NA).dropna(how='all')\n",
    "    default = default.dropna(how='all').replace('', pd.NA).dropna(how='all')\n",
    "    default.iloc[:, 4] = \"absence of \" + default.iloc[:, 4]\n",
    "\n",
    "    values = {data_PPL.columns[0]: 'Group'}\n",
    "    data_PPL.rename(columns=values, inplace=True)\n",
    "    data_PPL.iloc[:, 0] = data_PPL.iloc[:, 0].astype(str).str.strip()\n",
    "    data_PPL['Item'] = data_PPL.apply(\n",
    "        lambda row: model_class + \"-\"  + row[data_PPL.columns[0]] if pd.notnull(row[data_PPL.columns[0]]) and row[data_PPL.columns[0]] != 'nan' else row[data_PPL.columns[0]],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    values = {data_Var.columns[0]: 'Group', data_Var.columns[3]: 'Features'}\n",
    "    data_Var.rename(columns=values, inplace=True)\n",
    "    data_Var['Group'] = data_Var['Group'].fillna(method='ffill')\n",
    "    data_Var.loc[(data_Var['Features'].notnull()) & (data_Var['Features'] != 'nan'), 'Item'] = model_class + '-' + data_Var['Features']\n",
    "    data_Var['Item'] = data_Var['Item'].astype(str)\n",
    "    \n",
    "    data_Var['Group'] = model_class +'-'+ data_Var['Group']\n",
    "    data_Var_Bk = data_Var.copy()\n",
    "    data_Var = data_Var.dropna(subset=['Item'])\n",
    "    data_Var = data_Var[data_Var['Item'] != 'nan']\n",
    "\n",
    "    Grouped_var = data_Var.groupby('Group')['Features'].apply(lambda x: ' or '.join(x)).reset_index()\n",
    "    values = {'Item': 'Features', 'Group': 'Item'}\n",
    "    Grouped_var.rename(columns=values, inplace=True)\n",
    "\n",
    "    default['ref'] = 'default'\n",
    "    combination['ref'] = 'combination'\n",
    "    data_PPL['ref'] = 'PPL'\n",
    "    Grouped_var['ref'] = 'Variants_Options'\n",
    "\n",
    "\n",
    "    final = pd.concat([default, combination, data_PPL, Grouped_var], ignore_index=True)\n",
    "    values = {'Item': 'Group', 'Features': 'comibined_features'}\n",
    "    Grouped_var.rename(columns=values, inplace=True)\n",
    "    data_Var_Bk = pd.merge(data_Var_Bk, Grouped_var, on='Group', how='left')\n",
    "\n",
    "    final['Class'] = model_class\n",
    "    data_Var_Bk['Class'] = model_class\n",
    "\n",
    "    final_ = pd.concat([final_, final], axis=0)\n",
    "    data_Var_Bk_ = pd.concat([data_Var_Bk_, data_Var_Bk], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a3c22",
   "metadata": {},
   "source": [
    "## Reading files xls formate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22199fde-7f1f-4d60-9803-a336e76fd137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\_Projects\\FBOM\\\\Input\\2012.xls\n",
      "2012\n",
      "[455]\n",
      "E:\\_Projects\\FBOM\\\\Input\\2018.xls\n",
      "2018\n",
      "[102]\n",
      "E:\\_Projects\\FBOM\\\\Input\\2019.xls\n",
      "2019\n",
      "[74]\n",
      "E:\\_Projects\\FBOM\\\\Input\\2063.xls\n",
      "2063\n",
      "[75]\n",
      "E:\\_Projects\\FBOM\\\\Input\\6623.xls\n",
      "6623\n",
      "[244]\n",
      "E:\\_Projects\\FBOM\\\\Input\\6624.xls\n",
      "6624\n",
      "E:\\_Projects\\FBOM\\\\Input\\6627.xls\n",
      "6627\n",
      "[175]\n",
      "E:\\_Projects\\FBOM\\\\Input\\6628.xls\n",
      "6628\n",
      "[261]\n",
      "E:\\_Projects\\FBOM\\\\Input\\6681.xls\n",
      "6681\n",
      "E:\\_Projects\\FBOM\\\\Input\\6682.xls\n",
      "6682\n",
      "E:\\_Projects\\FBOM\\\\Input\\6684.xls\n",
      "6684\n",
      "E:\\_Projects\\FBOM\\\\Input\\6688.xls\n",
      "6688\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x in files:\n",
    "    print(x)\n",
    "   \n",
    "    match = re.search(r'\\\\(\\d{4})\\.xls$', x)\n",
    "    #print(match)\n",
    "    if match:\n",
    "        model_class = match.group(1)\n",
    "        print(model_class)\n",
    "        \n",
    "    else:\n",
    "        print(\"class not found in the file path\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        Single_Class(x,model_class)\n",
    "    except:\n",
    "        Multi_Class(x,model_class)\n",
    "       \n",
    "            \n",
    "\n",
    "final_.drop_duplicates(inplace=True)\n",
    "data_Var_Bk_.drop_duplicates(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e86ba3",
   "metadata": {},
   "source": [
    "## Reading file .xlsx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e4c113e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\_Projects\\FBOM\\\\Input\\2062.xlsx\n",
      "2062\n",
      "[303]\n",
      "E:\\_Projects\\FBOM\\\\Input\\2064.xlsx\n",
      "2064\n",
      "[190]\n",
      "E:\\_Projects\\FBOM\\\\Input\\2084.xlsx\n",
      "2084\n",
      "E:\\_Projects\\FBOM\\\\Input\\2088.xlsx\n",
      "2088\n",
      "E:\\_Projects\\FBOM\\\\Input\\6629.xlsx\n",
      "6629\n",
      "E:\\_Projects\\FBOM\\\\Input\\6658.xlsx\n",
      "6658\n",
      "[16]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x in files_excel:\n",
    "    print(x)\n",
    "   \n",
    "    match = re.search(r'\\\\(\\d{4})\\.xlsx$', x)\n",
    "    #print(match)\n",
    "    if match:\n",
    "        model_class = match.group(1)\n",
    "        print(model_class)\n",
    "        \n",
    "    else:\n",
    "        print(\"class not found in the file path\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        Single_Class(x,model_class)\n",
    "    except:\n",
    "        Multi_Class(x,model_class)\n",
    "       \n",
    "            \n",
    "\n",
    "final_.drop_duplicates(inplace=True)\n",
    "data_Var_Bk_.drop_duplicates(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb71c47c-3af3-46b8-a9d5-8fb4365e3dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_ = final_[Keep_Col + remaining_cols]\n",
    "final.loc[final['ref']=='Variants_Options','Item_new'] = final['Class'] + final['Item']\n",
    "data_Var_Bk_.to_csv(Path + 'Output\\\\Variants.csv', index=False)\n",
    "final_.to_csv(Path + 'Output\\\\Master.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8caa4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(Path+'Output\\\\FBOM.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Write each DataFrame to a specific sheet\n",
    "    final_.to_excel(writer, sheet_name='Master_sheet', index=False)\n",
    "    data_Var_Bk_.to_excel(writer, sheet_name='Variants_and_Options', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c33822f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status : Automation Completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "status = 'Status : Automation Completed'\n",
    "print(status)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
